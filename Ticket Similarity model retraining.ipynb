{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e58018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def query_engine(corpus,queries):\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar tickets matching your Query:\")\n",
    "\n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            print(int(idx), \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99406bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder2 = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "def query_engine_ml(corpus,queries):\n",
    "    corpus_embeddings = embedder2.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder2.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar tickets matching your Query:\")\n",
    "\n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            print(int(idx), \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543f78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618991ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=['this car came to us with a flashing urea lamp. message on display \"starting not possible within 400km\" car had error code P20EE in the ECU.so I ran TSB B1HW01KTQ0. the programming of the engine ECU did not go well, see attached photo. then carried out a manual telecoding, which also gave an error code, see photo I also have no communication with the Ad-bleu tank in this car. I also tried to n Ad-bleu tank via the CAN interface, but it immediately gave 5 green check marks, so it was already up to date. but communication with the tank via the CAN interface. tank is full, self-filled. but after the error code P20EE was no longer in the ECU, not even after a test drive.I can therefore not implement the last 2 points of the TSB.resetting the denox system fault codes as i have no communication guided diagnosis because I no longer have a fault P20EE',\n",
    "           'client goes to the workshop again, with urea and faults on, we downloaded it a few days ago but it has turned on again',\n",
    "           'eml on urea light on starting inhibited in 100 miles on display',\n",
    "           'the customer is complaining of a urea indicator light with message start impossible in 100kms + engine warning light',\n",
    "           'The customer complain that the urea system warning lamp has been lit up',\n",
    "           'engine light on with urea and service key on just ad blue made by the customer and without driving problems',\n",
    "           'voyant motor + adblue + breakdown',\n",
    "           'urea warning light is on',\n",
    "           'Vehicle is back in with engine light and urea lightson ,P20EE stored again, vehicle got a  urea injector last time due to visual sign of dried urea fluid coming from injector',\n",
    "           'p20ee in my ccm diag light on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f036b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"i have problem with ECU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc49409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: i have problem with ECU\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "0 (Score: 0.4072)\n",
      "2 (Score: 0.2310)\n",
      "3 (Score: 0.2258)\n",
      "9 (Score: 0.2027)\n",
      "7 (Score: 0.1851)\n"
     ]
    }
   ],
   "source": [
    "query_engine(corpus,queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3f692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_ml=[\n",
    "    'deze auto is bij ons binnen gekomen met een knipperde urea lamp. melding op display \"starten niet mogelijk binnen 400km\" auto had storing code P20EE in de ECU staan.dus ik heb TSB B1HW01KTQ0 uitgevoerd. bij  de van de motor ECU ging de programmering niet goed, zie bijgevoegde foto. daarna handmatig een telecodering uitgevoerd, deze gaf ook een foutcode, zie foto ook heb ik bij deze auto geen communicatie met de Ad-bleu tank. ik heb ook geprobeerd Ad-bleu tank via de CAN interface te n , maar deze gaf direct 5 groene vinkjes, dus hij was al up to date. maar wel communicatie met de tank via de CAN interface. tank is vol, zelf afgevuld. maar na de  was foutcode P20EE niet meer in de ECU ook niet na een proefrit. de laatste 2 punten van de TSB kan ik dus niet uitvoeren. resetten van de storingcodes van het denox-systeem, omdat ik geen communicatie heb geleide diagnose omdat ik geen storing P20EE meer heb',\n",
    "    'cliente acude de nuevo ataller , con urea y fallos encendiddos , hicimos hace unos dias telecarga pero ha vuelto a encender',\n",
    "    'eml on urea light on starting inhibited in 100 miles on display',\n",
    "    \"le client se plaitn d'un allumage voyant d'uree avec message demarrage impossible dans 100kms + temoin moteur\",\n",
    "    'the customer complain that the urea system warning lamp has been lit up',\n",
    "    'voyant moteur allume avec uree et cles de service allume pein ad blue fait par le client  et sans probleme de conduite',\n",
    "    'voyant moteur + adblue + decompte km',\n",
    "    '尿素警示燈亮',\n",
    "    'Vehicle is back in with engine light and urea lightson ,P20EE stored again, vehicle got a  urea injector last time due to visual sign of dried urea fluid coming from injector',\n",
    "    'p20ee dans mon ccm voyant diag allume'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90aa8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries2=['i have problem with urea light',\"j'ai un problème avec la lumière d'urée\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc908a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: i have problem with urea light\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "2 (Score: 0.5697)\n",
      "4 (Score: 0.4817)\n",
      "9 (Score: 0.4774)\n",
      "8 (Score: 0.4364)\n",
      "7 (Score: 0.4362)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: j'ai un problème avec la lumière d'urée\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "9 (Score: 0.5568)\n",
      "7 (Score: 0.5082)\n",
      "3 (Score: 0.4554)\n",
      "0 (Score: 0.4242)\n",
      "4 (Score: 0.4093)\n"
     ]
    }
   ],
   "source": [
    "query_engine_ml(sentences_ml,queries2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec9925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375800e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c22a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/embedding-data___json/embedding-data--flickr30k-captions-2712c8cf1b16a4cb/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0028f12ed305459bad0f238a17b11bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"embedding-data/flickr30k-captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c49b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['set'],\n",
       "        num_rows: 31783\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b44033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': ['A child in a pink dress is climbing up a set of stairs in an entry way.',\n",
       "  'A girl going into a wooden building.',\n",
       "  'A little girl climbing into a wooden playhouse',\n",
       "  'A little girl in a pink dress going into a wooden cabin.',\n",
       "  'A little girl climbing the stairs to her playhouse.']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71573c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': ['Four men on top of a tall structure.',\n",
       "  'Workers look down from up above on a piece of equipment.',\n",
       "  'Several men in hard hats are operating a giant pulley system.',\n",
       "  'Three men on a large rig.',\n",
       "  'Two men working on a machine wearing hard hats.']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc3e694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': ['A man riding a small boat in a harbor, with fog and mountains in the background.',\n",
       "  'A man in shorts and a Hawaiian shirt leans over the rail of a pilot boat, with fog and mountains in the background.',\n",
       "  'A young man hanging over the side of a boat, which is in a like with fog rolling over a hill behind it.',\n",
       "  'A man is leaning off of the side of a blue and white boat as it sits in a body of water.',\n",
       "  'A man on a moored blue and white boat with hills and mist in the background.']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][31782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "659a8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/embedding-data___json/embedding-data--coco_captions-18033e4d0db7f137/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779a104674974f799369d50723220c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset2 = load_dataset(\"embedding-data/coco_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a8901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': ['A clock that blends in with the wall hangs in a bathroom. ',\n",
       "  'A very clean and well decorated empty bathroom',\n",
       "  'A bathroom with a border of butterflies and blue paint on the walls above it.',\n",
       "  'An angled view of a beautifully decorated bathroom.',\n",
       "  'A blue and white bathroom with butterfly themed wall tiles.']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "387ed962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25a1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': ['A couple of women with some stuffed animals.',\n",
       "  'Two women smile for the camea while posing iwth some suffed animals ',\n",
       "  'Fans pose with stuffed animals at an ice rink.',\n",
       "  'Two women smiling together, one holds a stuffed animal the other has a stuffed animal on her shoulder.',\n",
       "  'Two women sit and pose with stuffed animals.']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[\"train\"][82782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d041f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6b18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1096a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347081, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./final cleaning/Cleaned_text_of_all_languages.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cb8679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21939    7708\n",
       "20060    6373\n",
       "24037    6256\n",
       "17210    3859\n",
       "3837     3675\n",
       "         ... \n",
       "30392       1\n",
       "36639       1\n",
       "35848       1\n",
       "23669       1\n",
       "19757       1\n",
       "Name: ID_HISTORICAL_TICKET_ID, Length: 8877, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ID_HISTORICAL_TICKET_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc066881",
   "metadata": {},
   "outputs": [],
   "source": [
    "morethan50 = data['ID_HISTORICAL_TICKET_ID'].value_counts()[data['ID_HISTORICAL_TICKET_ID'].value_counts()>49].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda8e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_50 = data[data['ID_HISTORICAL_TICKET_ID'].isin(morethan50[0:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "550fe738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21939    7708\n",
       "20060    6373\n",
       "24037    6256\n",
       "17210    3859\n",
       "3837     3675\n",
       "16729    3315\n",
       "19010    2403\n",
       "22353    2147\n",
       "22737    2051\n",
       "19951    1944\n",
       "Name: ID_HISTORICAL_TICKET_ID, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_50['ID_HISTORICAL_TICKET_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24186b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50 = data_50.groupby('ID_HISTORICAL_TICKET_ID').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b873335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16729    50\n",
       "22353    50\n",
       "20060    50\n",
       "21939    50\n",
       "17210    50\n",
       "24037    50\n",
       "19010    50\n",
       "19951    50\n",
       "3837     50\n",
       "22737    50\n",
       "Name: ID_HISTORICAL_TICKET_ID, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50['ID_HISTORICAL_TICKET_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78728c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4263557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950db379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tktlst=[]\n",
    "for hist_tkt in top_50['ID_HISTORICAL_TICKET_ID'].value_counts().index:\n",
    "    tkkts=[]\n",
    "    tkkts = top_50[top_50['ID_HISTORICAL_TICKET_ID']==hist_tkt]['clean_text_3'].to_list()\n",
    "    tkss_strip = [t.strip() for t in tkkts]\n",
    "    tktlst.append(tkss_strip)\n",
    "\n",
    "d1 = datasets.Dataset.from_dict({'set':tktlst})\n",
    "dd = datasets.DatasetDict({'train':d1})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a4ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['set'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d54fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8851cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9811db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "train_data = dd['train']['set']\n",
    "n_examples = dd['train'].num_rows\n",
    "\n",
    "for i in range(n_examples):\n",
    "  example = train_data[i]\n",
    "  train_examples.append(InputExample(texts=example[0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97e0ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "num_epochs = 2\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e74489f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf20378b40d4f8fbb0354ab2fe43238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b57f02db28246ddbd255ab2db3aa8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952dc6b6ad8d499cbf5bf426055890c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6ee23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./ticket_similarity_model/ticketsimilarity_xlm-r-distilroberta-base-paraphrase-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45cd21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06b7775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_custom = SentenceTransformer('./ticket_similarity_model/ticketsimilarity_xlm-r-distilroberta-base-paraphrase-v1/')\n",
    "\n",
    "def query_engine_custom_ml(corpus,queries):\n",
    "    corpus_embeddings = embedder_custom.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder_custom.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar tickets matching your Query:\")\n",
    "\n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            print(int(idx), \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "533a52b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have changed the Airbag computer because of internal defect in the old one . Now when i have changed it i can't configurate or download software to the airbag or the BSI . Fault-code from BSI is B10AA. The confugure in BSI is the same as in Airbag computer . My diagboix version is 09.103 . the airbag fault-lamp is activated permanent with no fault code is Airbag\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ID_HISTORICAL_TICKET_ID']==16729].iloc[51].DS_REPAIRER_LANGUAGE_TICKET_ADDITIONAL_DESC    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "the airbag fault lamp is activated permanent with no fault code is airbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e0693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = data[data['ID_HISTORICAL_TICKET_ID']==16729].iloc[52:72]['clean_text_3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b079c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quer = [\"the airbag fault lamp is activated permanent with no fault code in airbag\",\"le voyant de défaut de l'airbag est activé en permanence sans code d'erreur dans l'airbag\",\"die airbag-fehlerlampe leuchtet dauerhaft und es liegt kein fehlercode im airbag vor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d8a394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: the airbag fault lamp is activated permanent with no fault code in airbag\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.6357)\n",
      "12 (Score: 0.4984)\n",
      "2 (Score: 0.4800)\n",
      "6 (Score: 0.4789)\n",
      "10 (Score: 0.4743)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: le voyant de défaut de l'airbag est activé en permanence sans code d'erreur dans l'airbag\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.7179)\n",
      "12 (Score: 0.5496)\n",
      "2 (Score: 0.5273)\n",
      "17 (Score: 0.5271)\n",
      "16 (Score: 0.5165)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: die airbag-fehlerlampe leuchtet dauerhaft und es liegt kein fehlercode im airbag vor\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.6701)\n",
      "12 (Score: 0.5427)\n",
      "6 (Score: 0.5339)\n",
      "2 (Score: 0.5192)\n",
      "10 (Score: 0.5189)\n"
     ]
    }
   ],
   "source": [
    "query_engine_custom_ml(sent,quer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a8868c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: the airbag fault lamp is activated permanent with no fault code in airbag\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.5345)\n",
      "2 (Score: 0.3718)\n",
      "10 (Score: 0.3427)\n",
      "17 (Score: 0.3422)\n",
      "3 (Score: 0.3289)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: le voyant de défaut de l'airbag est activé en permanence sans code d'erreur dans l'airbag\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.6302)\n",
      "17 (Score: 0.4352)\n",
      "13 (Score: 0.4330)\n",
      "2 (Score: 0.4053)\n",
      "12 (Score: 0.3901)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: die airbag-fehlerlampe leuchtet dauerhaft und es liegt kein fehlercode im airbag vor\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "15 (Score: 0.5963)\n",
      "13 (Score: 0.4142)\n",
      "2 (Score: 0.4119)\n",
      "16 (Score: 0.4088)\n",
      "12 (Score: 0.4025)\n"
     ]
    }
   ],
   "source": [
    "query_engine_ml(sent,quer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a2b7f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die airbag-fehlerlampe leuchtet dauerhaft und es liegt kein fehlercode im airbag vor'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Die Airbag-Fehlerlampe leuchtet dauerhaft und es liegt kein Fehlercode im Airbag vor\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41e42844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FR    22\n",
       "DE    11\n",
       "ES     6\n",
       "PT     3\n",
       "NL     2\n",
       "EN     2\n",
       "JA     1\n",
       "TR     1\n",
       "HE     1\n",
       "IT     1\n",
       "Name: CD_REPAIRER_LANGUAGE_ISO_CODE, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ID_HISTORICAL_TICKET_ID']==16729].iloc[0:50]['CD_REPAIRER_LANGUAGE_ISO_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce26c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51933614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd72c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347081, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./final cleaning/Cleaned_text_of_all_languages.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4998b44",
   "metadata": {},
   "source": [
    "# training on all historical tickets(347K) with 105 sentences per ticket(balanced basis on language)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "211d476f",
   "metadata": {},
   "source": [
    "FR    15\n",
    "ES    15\n",
    "DE    15\n",
    "EN    15\n",
    "PT    15\n",
    "IT    15\n",
    "Others 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e343fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs=['FR', 'ES', 'DE', 'EN', 'PT', 'IT'] #first 6\n",
    "other_langs=['NL', 'DA', 'PL', 'NO', 'SV', 'HE',\n",
    "       'CS', 'TR', 'FI', 'JA', 'HR', 'HU', 'RO', 'SL', 'SK', 'EL', 'GB', 'RU',\n",
    "       'ZH', 'UK', 'AR', 'ET', 'MS', 'LV', 'LT', 'BG', 'TN', 'SR', 'MK', 'VN',\n",
    "       'DK', 'SE', 'KO', 'BE', 'BR', 'TH', 'PF', 'BS', 'JP', 'CN', 'SI', 'CH',\n",
    "       'EE', 'IL', 'CL', 'UA', 'IS', 'AD', 'AT', 'CZ', 'EC', 'GP', 'MG', 'DS',\n",
    "       'DZ', 'MQ', 'ZN', 'GR', 'N', 'NE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7b1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length_clean_text']=data['clean_text_3'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0a0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_50chars = data[data['length_clean_text']>=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d2d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_tickets = data_50chars['ID_HISTORICAL_TICKET_ID'].value_counts()[data_50chars['ID_HISTORICAL_TICKET_ID'].value_counts()>=105].index #histtickets with atleast 105 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ac8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n_sentence_tickets = data_50chars[data_50chars['ID_HISTORICAL_TICKET_ID'].isin(hist_tickets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ab49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b59bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hst_tkt in hist_tickets:\n",
    "    df_hist_tkt = data_n_sentence_tickets[data_n_sentence_tickets['ID_HISTORICAL_TICKET_ID']==hst_tkt]\n",
    "    df_hist_tkt_balanced_toplangs = df_hist_tkt[df_hist_tkt['CD_REPAIRER_LANGUAGE_ISO_CODE'].isin(langs)].groupby([\"CD_REPAIRER_LANGUAGE_ISO_CODE\"]).head(15)\n",
    "    df_hist_tkt_balanced_otherlangs = df_hist_tkt[df_hist_tkt['CD_REPAIRER_LANGUAGE_ISO_CODE'].isin(other_langs)].head(15)\n",
    "    df_tkt_balanced = pd.concat([df_hist_tkt_balanced_toplangs,df_hist_tkt_balanced_otherlangs], ignore_index=True, axis=0)\n",
    "    df_balanced = pd.concat([df_balanced,df_tkt_balanced], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac67766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34365, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af3fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hist_tikts = df_balanced['ID_HISTORICAL_TICKET_ID'].value_counts()[df_balanced['ID_HISTORICAL_TICKET_ID'].value_counts()==105].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29818ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_final = df_balanced[df_balanced['ID_HISTORICAL_TICKET_ID'].isin(final_hist_tikts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663c6568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5040"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_hist_tikts)*105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f8e5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5040, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f405863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_hist_tikts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ade286",
   "metadata": {},
   "source": [
    "#### 48 historical tickets left which has 105 sentences with atleast 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc77639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78d398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    tktlst=[]\n",
    "    \n",
    "    for hist_tkt in df_balanced_final['ID_HISTORICAL_TICKET_ID'].value_counts().index:\n",
    "        tkkts=[]\n",
    "        tkkts = df_balanced_final[df_balanced_final['ID_HISTORICAL_TICKET_ID']==hist_tkt]['clean_text_3'].to_list()\n",
    "        tkss_strip = [t.strip() for t in tkkts]\n",
    "        tktlst.append(tkss_strip)\n",
    "        \n",
    "    d1 = datasets.Dataset.from_dict({'set':tktlst})\n",
    "    dd = datasets.DatasetDict({'train':d1})  \n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "771adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1755634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "427856c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_example(dd):\n",
    "    train_examples = []\n",
    "    train_data = dd['train']['set']\n",
    "    n_examples = dd['train'].num_rows\n",
    "\n",
    "    for i in range(n_examples):\n",
    "      example = train_data[i]\n",
    "      train_examples.append(InputExample(texts=example[0:105]))\n",
    "    \n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "254f0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = prepare_input_example(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2d236e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7d5e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5991d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20c30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbaa3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "num_epochs = 2\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af782802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92dcc82167a4b158e36dcb161fb12fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a9b7c5ae194004a95b61d833870b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de40ebf1df0c4cc7b50a81a8d0cf0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,show_progress_bar=True,\n",
    "          checkpoint_path = \"./ticket_similarity_model/\",\n",
    "          checkpoint_save_steps = 6      \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7562894",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./ticket_similarity_model/ticketsimilarity_xlm-r-distilroberta-base-paraphrase-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b3479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da57b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_custom = SentenceTransformer('./ticket_similarity_model/ticketsimilarity_xlm-r-distilroberta-base-paraphrase-v2/')\n",
    "\n",
    "def query_engine_custom_ml2(corpus,queries):\n",
    "    corpus_embeddings = embedder_custom.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder_custom.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar tickets matching your Query:\")\n",
    "\n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            print(int(idx), \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eed3ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: download of engine ecu failed now engine wont start\n",
      "\n",
      "Top 5 most similar tickets matching your Query:\n",
      "3 (Score: 0.7488)\n",
      "11 (Score: 0.6018)\n",
      "17 (Score: 0.5992)\n",
      "2 (Score: 0.5905)\n",
      "18 (Score: 0.5897)\n"
     ]
    }
   ],
   "source": [
    "query_engine_custom_ml2(sent,[\"download of engine ecu failed now engine wont start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abac1cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' pm27 logiciel diagbox  de  p22   erentiel rpo majim deion du    a e  de telement moteur le   demarre  avec e  de   404pendant le telement cdlt'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7df8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ec5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mteb\n",
      "  Downloading mteb-1.0.2-py3-none-any.whl (88 kB)\n",
      "                                              0.0/88.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 88.1/88.1 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: datasets>=2.2.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (2.13.1)\n",
      "Collecting jsonlines (from mteb)\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (1.10.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (2.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (2.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mteb) (4.65.0)\n",
      "Collecting rich (from mteb)\n",
      "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "                                              0.0/239.4 kB ? eta -:--:--\n",
      "     -------------------------------------  235.5/239.4 kB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  235.5/239.4 kB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 239.4/239.4 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (1.5.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (0.15.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.2.0->mteb) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->mteb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->mteb) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->mteb) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->mteb) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.0.2->mteb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.0.2->mteb) (3.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.2.0->mteb) (4.30.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.2.0->mteb) (0.15.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.2.0->mteb) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.2.0->mteb) (0.1.99)\n",
      "Requirement already satisfied: filelock in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->mteb) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->mteb) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->mteb) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->mteb) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->mteb) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->mteb) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonlines->mteb) (23.1.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->mteb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "                                              0.0/87.5 kB ? eta -:--:--\n",
      "     -------------------------------------    81.9/87.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 87.5/87.5 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->mteb) (2.15.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=2.2.0->mteb) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=2.2.0->mteb) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.3.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->mteb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch->mteb) (2.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers>=2.2.0->mteb) (8.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=2.2.0->mteb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=2.2.0->mteb) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch->mteb) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence-transformers>=2.2.0->mteb) (9.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\v.sai.teja.kukunuri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets>=2.2.0->mteb) (1.16.0)\n",
      "Installing collected packages: mdurl, jsonlines, markdown-it-py, rich, mteb\n",
      "Successfully installed jsonlines-3.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mteb-1.0.2 rich-13.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mteb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b477c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import MTEB\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d631837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./ticket_similarity_model/ticketsimilarity_xlm-r-distilroberta-base-paraphrase-v2/\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510ca77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = MTEB(tasks=[\"STS22\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb175173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">STS</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSTS\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - STS22, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">p2p</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-style: italic\">crosslingual </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">18</span><span style=\"color: #008080; text-decoration-color: #008080; font-style: italic\"> pairs</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - STS22, \u001b[3;38;5;241mp2p\u001b[0m, \u001b[3;36mcrosslingual \u001b[0m\u001b[1;3;36m18\u001b[0m\u001b[3;36m pairs\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sts22-crosslingual-sts/en to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/de to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/es to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/pl to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/tr to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/tr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/tr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/ar to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/ar/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/ar/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/ru to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/ru/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/ru/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/zh to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/zh/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/zh/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/fr to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/fr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/fr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/de-en to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/es-en to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/it to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/it/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/it/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/pl-en to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/pl-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/pl-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/zh-en to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/zh-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/zh-en/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/es-it to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es-it/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/es-it/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/de-fr to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-fr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-fr/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset sts22-crosslingual-sts/de-pl to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/de-pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sts22-crosslingual-sts/fr-pl to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/fr-pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1...\n",
      "Dataset sts22-crosslingual-sts downloaded and prepared to C:/Users/v.sai.teja.kukunuri/.cache/huggingface/datasets/mteb___sts22-crosslingual-sts/fr-pl/1.0.0/563d7d9067b4162f5e964eb988aaa492b59e7ed47a03f16ec94e19b0e60ee8c1. Subsequent calls will reuse this data.\n",
      "\n",
      "Task: STS22, split: test, language: en. Running...\n",
      "\n",
      "Task: STS22, split: test, language: de. Running...\n",
      "\n",
      "Task: STS22, split: test, language: es. Running...\n",
      "\n",
      "Task: STS22, split: test, language: pl. Running...\n",
      "\n",
      "Task: STS22, split: test, language: tr. Running...\n",
      "\n",
      "Task: STS22, split: test, language: ar. Running...\n",
      "\n",
      "Task: STS22, split: test, language: ru. Running...\n",
      "\n",
      "Task: STS22, split: test, language: zh. Running...\n",
      "\n",
      "Task: STS22, split: test, language: fr. Running...\n",
      "\n",
      "Task: STS22, split: test, language: de-en. Running...\n",
      "\n",
      "Task: STS22, split: test, language: es-en. Running...\n",
      "\n",
      "Task: STS22, split: test, language: it. Running...\n",
      "\n",
      "Task: STS22, split: test, language: pl-en. Running...\n",
      "\n",
      "Task: STS22, split: test, language: zh-en. Running...\n",
      "\n",
      "Task: STS22, split: test, language: es-it. Running...\n",
      "\n",
      "Task: STS22, split: test, language: de-fr. Running...\n",
      "\n",
      "Task: STS22, split: test, language: de-pl. Running...\n",
      "\n",
      "Task: STS22, split: test, language: fr-pl. Running...\n"
     ]
    }
   ],
   "source": [
    "results = evaluation.run(model, output_folder=f\"./ticket_similarity_model/MTEBresults/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f535dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
